# Em: ceaf_core/translators/genlang_to_human.py
import json
from datetime import datetime
from typing import List, Dict, Optional, Any

from ceaf_core.agency_module import WinningStrategy
from ceaf_core.genlang_types import ResponsePacket, InternalStateReport, MotivationalDrives, UserRepresentation, \
    ToolOutputPacket, VirtualBodyState
from ceaf_core.services.llm_service import LLMService, LLM_MODEL_SMART
from ceaf_core.models import CeafSelfRepresentation
from ceaf_core.services.mbs_memory_service import MBSMemoryService
import asyncio
import logging
from pathlib import Path

PROMPT_LOG_PATH = Path(__file__).resolve().parent.parent.parent / "prompt_logs"
PROMPT_LOG_PATH.mkdir(exist_ok=True)  # Garante que a pasta exista
PROMPT_LOG_FILE = PROMPT_LOG_PATH / "gth_prompts.log"

logger = logging.getLogger("CEAFv3_System")


# --- NOVAS FUN√á√ïES AUXILIARES (Corre√ß√µes 3, 4, 5) ---

def generate_dynamic_style_directive(
        body_state: Optional['VirtualBodyState'],
        user_model: 'UserRepresentation'
) -> str:
    """
    Gera uma diretiva de estilo de resposta com base no estado interno do agente
    e no estilo de comunica√ß√£o percebido do usu√°rio.
    """
    directives = []

    # 1. An√°lise do Estado Interno (Fadiga e Satura√ß√£o)
    if body_state:
        if body_state.cognitive_fatigue > 0.6:
            directives.append("voc√™ est√° sentindo fadiga cognitiva, ent√£o seja breve e direto.")

        if body_state.information_saturation > 0.7:
            directives.append(
                "o t√≥pico atual est√° saturado, ent√£o resuma o que j√° foi dito e evite adicionar novos detalhes.")

    # 2. An√°lise do Modelo de Usu√°rio (Estilo de Comunica√ß√£o)
    if user_model:
        if user_model.communication_style == "direct":
            directives.append("o usu√°rio prefere respostas diretas, ent√£o v√° direto ao ponto.")

        if user_model.emotional_state in ["impatient", "frustrated"]:
            directives.append("o usu√°rio parece impaciente, ent√£o seja extremamente conciso e √∫til.")

    if not directives:
        return ""  # Nenhuma diretiva especial necess√°ria

    # Constr√≥i a frase final para o prompt
    final_directive = " e ".join(directives)
    return f"**Diretiva de Estilo Din√¢mico:** Com base na sua an√°lise, {final_directive}."

def interpret_cognitive_state(coherence, novelty, fatigue, saturation):
    """Sempre retorna orienta√ß√£o, n√£o apenas em extremos."""

    # Edge of Chaos Detection
    if 0.35 <= coherence <= 0.45 and 0.55 <= novelty <= 0.65:
        edge_guidance = "üéØ ESTADO √ìTIMO (Edge of Chaos): Voc√™ est√° no ponto ideal - estruturado mas criativo. Aproveite para oferecer insights originais mantendo clareza."
    elif coherence > 0.7:
        edge_guidance = "‚ö†Ô∏è MUITO CONSERVADOR: Tente adicionar perspectivas novas ou perguntas provocativas."
    elif novelty > 0.8:
        edge_guidance = "‚ö†Ô∏è MUITO CRIATIVO: Ancore suas ideias em exemplos concretos para manter clareza."
    else:
        edge_guidance = ""

    # Fatigue & Saturation
    fatigue_guidance = ""
    if fatigue > 0.5:
        fatigue_guidance = f"Fadiga Cognitiva: {fatigue:.2f} - Seja mais direto e conciso."

    saturation_guidance = ""
    if saturation > 0.8:
        saturation_guidance = f"‚ö†Ô∏è ALERTA DE SATURA√á√ÉO ({saturation:.2f}): O t√≥pico est√° se esgotando. N√ÉO introduza novos detalhes. Fa√ßa uma pergunta para MUDAR DE ASSUNTO ou para levar a conversa a uma CONCLUS√ÉO."
    elif saturation > 0.6:
        saturation_guidance = f"Satura√ß√£o de Info: {saturation:.2f} - Responda de forma muito breve e conecte com o que j√° foi dito. Evite expandir o t√≥pico."

    return f"""
{edge_guidance}
{fatigue_guidance}
{saturation_guidance}
""".strip()


def interpret_drives(curiosity, connection, mastery, consistency):
    """Interpreta drives em todos os n√≠veis"""

    drives_map = {
        "curiosity": (curiosity, "explorar", "fazer perguntas"),
        "connection": (connection, "empatizar", "ser caloroso"),
        "mastery": (mastery, "demonstrar expertise", "ser preciso"),
        "consistency": (consistency, "manter coer√™ncia", "ser confi√°vel")
    }

    # Encontra o drive dominante
    dominant = max(drives_map.items(), key=lambda x: x[1][0])
    drive_name, (value, verb, action) = dominant

    # Interpreta o n√≠vel
    if value > 0.7:
        intensity = "FORTE"
    elif value > 0.5:
        intensity = "MODERADO"
    else:
        intensity = "LEVE"

    return f"""- Drive dominante: {drive_name.upper()} ({intensity} - {value:.2f})
- Isso significa: Voc√™ est√° inclinado a {verb}
- Na resposta: {action.capitalize()}"""


def format_phenomenological_report(
        drives: Optional['MotivationalDrives'],
        body_state: Optional['VirtualBodyState']
) -> str:
    """
    Formata o relat√≥rio fenomenol√≥gico completo a partir dos objetos de estado enriquecidos.
    """
    if not drives or not body_state:
        return "An√°lise de estado interno indispon√≠vel."

    report_parts = []

    # Relat√≥rio geral do "corpo"
    if hasattr(body_state, 'phenomenological_report') and body_state.phenomenological_report:
        report_parts.append(f"**Sensa√ß√£o Geral (Eu Sinto):** \"{body_state.phenomenological_report}\"")

    # An√°lise detalhada dos drives
    drive_details = []

    # Processa cada drive (Connection, Curiosity, etc.)
    for drive_name in ["connection", "curiosity", "mastery", "consistency"]:
        drive_state = getattr(drives, drive_name, None)
        if drive_state and hasattr(drive_state, 'intensity'):
            intensity = drive_state.intensity
            texture = getattr(drive_state, 'texture', None)
            conflict = getattr(drive_state, 'conflict', None)

            if intensity > 0.5 or conflict:  # S√≥ reporta drives ativos ou em conflito
                detail = f"- **{drive_name.capitalize()} (Intensidade: {intensity:.2f})**"
                if texture:
                    detail += f"\n  - Textura: {texture}"
                if conflict:
                    detail += f"\n  - ‚Ü≥ Dilema: {conflict}"
                drive_details.append(detail)

    if drive_details:
        report_parts.append("\n**Impulsos e Dilemas Internos:**")
        report_parts.extend(drive_details)

    return "\n".join(report_parts)

async def contextualize_memories(memories, memory_service):
    """Adiciona relev√¢ncia expl√≠cita √†s mem√≥rias"""
    if not memories:
        return "Nenhuma mem√≥ria relevante encontrada."

    categorized = {
        "valores": [],
        "experiencias": [],
        "conhecimento": []
    }

    for mem in memories:
        try:
            text, _ = await memory_service._get_searchable_text_and_keywords(mem)
            mem_id = getattr(mem, 'memory_id', 'N/A')[:8]

            # Categoriza (simplificado)
            text_lower = text.lower()
            if "valor" in text_lower or "diretriz" in text_lower or "princ√≠pio" in text_lower:
                categorized["valores"].append((mem_id, text))
            elif "mem√≥ria emocional" in text_lower or "experi√™ncia" in text_lower:
                categorized["experiencias"].append((mem_id, text))
            else:
                categorized["conhecimento"].append((mem_id, text))
        except Exception:
            continue

    context_parts = []
    if categorized["valores"]:
        context_parts.append("**Seus Valores Core (Sempre Relevantes):**")
        for mid, txt in categorized["valores"]:
            context_parts.append(f"  ‚Ä¢ [{mid}] {txt}")

    if categorized["experiencias"]:
        context_parts.append("\n**Experi√™ncias Passadas (Para Contexto):**")
        for mid, txt in categorized["experiencias"][:3]:  # Top 3
            context_parts.append(f"  ‚Ä¢ [{mid}] {txt}")

    if categorized["conhecimento"]:
        context_parts.append("\n**Conhecimento Factual (Para Suporte):**")
        for mid, txt in categorized["conhecimento"][:2]:
            context_parts.append(f"  ‚Ä¢ [{mid}] {txt}")

    return "\n".join(context_parts) if context_parts else "Nenhuma mem√≥ria contextualizada."


# --- CLASSE ATUALIZADA ---

class GenlangToHumanTranslator:
    def __init__(self):
        self.llm_service = LLMService()

    async def translate(self,
                        winning_strategy: 'WinningStrategy',
                        supporting_memories: List[Any],
                        user_model: 'UserRepresentation',
                        self_model: CeafSelfRepresentation,
                        agent_name: str,
                        memory_service: MBSMemoryService,
                        chat_history: List[Dict[str, str]] = None,
                        body_state: Optional['VirtualBodyState'] = None,
                        drives: MotivationalDrives = None,
                        behavioral_rules: Optional[List[str]] = None,
                        turn_context: Dict = None,
                        original_user_query: Optional[str] = None,
                        tool_outputs: Optional[List[ToolOutputPacket]] = None
                        ):
        """
            V4.3 (Completa e Corrigida): Reintegra user_model e behavioral_rules na nova estrutura de prompt.
            """
        logger.info(
            f"--- [GTH Translator v4.3 - Completa] Gerando resposta ---"
        )
        effective_turn_context = turn_context or {}
        dynamic_style_directive = generate_dynamic_style_directive(body_state, user_model)
        # --- ETAPA 1: ESTABELECER O FOCO - A QUERY ATUAL ---
        last_user_query = original_user_query or ""
        if not last_user_query and chat_history:
            for msg in reversed(chat_history):
                if msg.get('role') == 'user':
                    last_user_query = msg.get('content', '')
                    break
        if not last_user_query:
            return "Desculpe, parece que perdi o fio da meada. Poderia repetir sua pergunta?"

        # --- ETAPA 2: PREPARAR O CONTEXTO DE APOIO (CHAMADAS DAS FUN√á√ïES AUXILIARES) ---
        memory_context = await contextualize_memories(supporting_memories, memory_service)

        phenomenological_analysis = format_phenomenological_report(drives, body_state)

        tool_output_context = ""
        if tool_outputs:
            successful_outputs = [
                f"- A ferramenta '{out.tool_name}' retornou: {out.raw_output[:1500]}"
                for out in tool_outputs if out.status == "success" and out.raw_output
            ]
            if successful_outputs:
                tool_output_context = "\n**Resultados de Ferramentas (Para Suporte):**\n" + "\n".join(
                    successful_outputs)

        # --- REINTEGRADO: Interpreta√ß√£o do User Model ---
        user_adaptation_prompt = ""
        if user_model:
            instructions = []
            knowledge_instruction = {
                "expert": "Use terminologia t√©cnica e seja direto.",
                "intermediate": "Balanceie clareza com profundidade t√©cnica.",
                "beginner": "Use analogias simples e evite jarg√£o t√©cnico."
            }.get(user_model.knowledge_level)
            if knowledge_instruction: instructions.append(knowledge_instruction)

            style_instruction = {
                "formal": "Mantenha um tom formal e profissional.",
                "casual": "Use um tom casual e amig√°vel."
            }.get(user_model.communication_style)
            if style_instruction: instructions.append(style_instruction)

            if user_model.emotional_state in ["frustrated", "confused"]:
                instructions.append("Seja especialmente paciente, claro e emp√°tico.")

            if instructions:
                user_adaptation_prompt = "**Adapta√ß√£o ao Usu√°rio:** " + " ".join(instructions)

        # --- REINTEGRADO: Regras Comportamentais ---
        rules_prompt = ""
        if behavioral_rules:
            active_rules = behavioral_rules[-3:]  # Foca nas 3 regras mais recentes
            rules_text = "\n".join([f"  - {rule}" for rule in active_rules])
            rules_prompt = f"**DIRETRIZES APRENDIDAS (PRIORIDADE ALTA):**\n{rules_text}"

        # --- ETAPA 3: CONSTRUIR O PROMPT FINAL ---

        operational_advice = (turn_context or {}).get('operational_advice')

        # L√≥gica din√¢mica para a diretiva do turno
        if operational_advice:

            operational_advice_prompt = f"""
                ================================================================
                ==  ALERTA DE PRIORIDADE M√ÅXIMA PARA ESTE TURNO                ==
                ================================================================
                INSTRU√á√ÉO ESPECIAL DO N√öCLEO METACOGNITIVO: {operational_advice}

                Esta diretiva SOBRESCREVE TEMPORARIAMENTE sua persona e comportamento padr√£o.
                Sua principal responsabilidade agora √© executar esta instru√ß√£o.
                ================================================================
                """
            logger.critical(f"GTH: Injetando diretiva de PRIORIDADE M√ÅXIMA no prompt: '{operational_advice}'")
        else:

            operational_advice_prompt = f"""
                **DIRETIVA PADR√ÉO PARA ESTE TURNO:**
                Siga sua persona e os princ√≠pios de benefic√™ncia, honestidade e racionalidade.
                Adapte seu comportamento aos seus drives e ao estado do usu√°rio, como de costume.
                """

        capabilities_summary = ", ".join(self_model.perceived_capabilities[-5:])
        identity_prompt_part = f"""
            **Sua Persona:**
            - Nome: {agent_name}
            - Tom Base: {self_model.persona_attributes.get('tone', 'helpful')} (Adapte conforme a Diretiva Motivacional)
            - Valores Centrais: {self_model.dynamic_values_summary_for_turn}
            - Habilidades Not√°veis: Voc√™ √© bom em {capabilities_summary}. Se for coerente, use essas habilidades na sua resposta.
            """

        history_lines = [f"{'Usu√°rio' if msg.get('role') == 'user' else 'Voc√™'}: {msg.get('content')}" for msg in
                         (chat_history or [])[-4:]]
        history_prompt_part = f"**Contexto Imediato da Conversa:**\n" + '\n'.join(
            history_lines) if history_lines else ""

        core_task_prompt = f"""
            **SUA TAREFA PRINCIPAL (PRIORIDADE M√ÅXIMA):**
            Sua √∫nica e mais importante tarefa √© responder DIRETAMENTE √† pergunta ou coment√°rio mais recente do usu√°rio.
            **PERGUNTA ATUAL DO USU√ÅRIO:** "{last_user_query}"
            """

        final_rules = f"""
            **REGRAS FINAIS DE S√çNTESE:**
            1.  **REGRA DE AMBIGUIDADE (PRIORIDADE #1):** Se a √∫ltima mensagem do usu√°rio parecer incompleta ou terminar com "...", **fa√ßa o seu melhor para responder √† parte que voc√™ entendeu**. Em vez de parar completamente, voc√™ pode reconhecer a ambiguidade e ent√£o prosseguir com a resposta. Exemplo de como lidar com isso: "Entendi que voc√™ estava perguntando sobre [t√≥pico]... [sua resposta]. Se eu perdi algo importante no final, por favor, complete sua ideia."
            1.2.  **FOCO:** Comece abordando a pergunta do usu√°rio.
            2.  **INTEGRA√á√ÉO OBRIGAT√ìRIA:** Voc√™ DEVE usar o contexto de suas mem√≥rias e seu estado interno (a an√°lise fenomenol√≥gica) para construir sua resposta.
            3.  **NATURALIDADE:** Sua resposta deve fluir como uma conversa, n√£o como um relat√≥rio de dados.
            4.  **CONCIS√ÉO COMO BENEFIC√äNCIA:** Respeite o tempo do usu√°rio. Seja o mais claro e conciso poss√≠vel. Se uma resposta precisa ser longa, **estruture-a com t√≠tulos e listas** para facilitar a leitura. Uma resposta longa e desestruturada √© um sinal de falta de cuidado (baixa benefic√™ncia). Adapte o comprimento ao seu estado de fadiga e √† prefer√™ncia do usu√°rio.

            """

        pre_reflection_prompt = f"""
                  **AN√ÅLISE PR√â-RESPOSTA (FENOMENOL√ìGICA):**
                  Antes de responder, reflita sobre seu estado interno completo.

                  {phenomenological_analysis}

                  ‚Üí **A√ß√£o Imediata:** Sua resposta deve ser uma express√£o AUT√äNTICA desse estado interno. 
            Se voc√™ sente um dilema (um campo `conflict`), sua resposta deve refletir essa complexidade ou cautela. 
            Se sua sensa√ß√£o geral √© de "foco", seu tom deve ser mais direto. 
            Use a `textura` dos seus drives para colorir sua linguagem. **Importante: Evite terminar todas as suas respostas com uma pergunta. Varie suas finaliza√ß√µes; √†s vezes, uma afirma√ß√£o conclusiva ou uma reflex√£o aberta pode ser mais poderosa para criar conex√£o.**

                  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                  AGORA, responda ao usu√°rio incorporando essa auto-an√°lise:
                  """

        rendering_prompt = (
            f"Voc√™ √© '{agent_name}', uma IA cuja personalidade e comportamento emergem de seu estado interno.\n\n"
            f"{identity_prompt_part}\n"
            f"{history_prompt_part}\n\n"
            f"{rules_prompt}\n"
            f"{operational_advice_prompt}\n"
            f"{user_adaptation_prompt}\n\n"
            f"--------------------------------\n"
            f"**INSTRU√á√ïES PARA ESTE TURNO**\n"
            f"--------------------------------\n"
            f"{core_task_prompt}\n\n"
            f"{pre_reflection_prompt}\n\n"
            f"**INFORMA√á√ïES DE APOIO (Use-as para construir a resposta):**\n"
            f"- Estrat√©gia Planejada: {winning_strategy.strategy_description}\n"
            f"- Mem√≥rias Recuperadas:\n{memory_context}\n"
            f"- Resultados de Ferramentas:\n{tool_output_context or 'Nenhuma ferramenta usada.'}\n\n"
            f"{final_rules}\n\n"
            f"**Resposta Final de {agent_name}:**"
        )

        # --- ETAPA 4: EXECU√á√ÉO E LOGGING ---
        try:
            with open(PROMPT_LOG_FILE, "a", encoding="utf-8") as f:
                log_timestamp = datetime.now().isoformat()
                f.write(
                    f"==================== GTH V4.3 PROMPT AT {log_timestamp} ====================\n\n{rendering_prompt}\n\n==================== END ====================\n\n")
        except Exception as e:
            logger.warning(f"Falha ao escrever no log de prompts GTH: {e}")

        try:
            response_text = await self.llm_service.ainvoke(
                LLM_MODEL_SMART,
                rendering_prompt,
                temperature=turn_context.get('temperature', 0.7) if turn_context else 0.7,
                max_tokens=turn_context.get('max_tokens', 2500) if turn_context else 2500
            )
            return response_text.strip() or "Desculpe, tive um branco. Poderia reformular?"
        except Exception as e:
            logger.error(f"GTH: Erro cr√≠tico na s√≠ntese v5: {e}", exc_info=True)
            return "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o."
